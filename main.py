"""
ì „ì²´ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""
import os
import argparse
import pandas as pd
import time
from tqdm import tqdm
from src import config, data_processing, train, evaluate, predict, utils

def main():
    # ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description='AutoGluon ML Pipeline')
    parser.add_argument('--data-only', action='store_true', help='ë°ì´í„° ì „ì²˜ë¦¬ë§Œ ì‹¤í–‰')
    parser.add_argument('--train-only', action='store_true', help='ëª¨ë¸ í•™ìŠµë§Œ ì‹¤í–‰')
    parser.add_argument('--evaluate-only', action='store_true', help='ëª¨ë¸ í‰ê°€ë§Œ ì‹¤í–‰')
    parser.add_argument('--num-targets', type=int, default=None, help='ì²˜ë¦¬í•  íƒ€ê²Ÿ ì»¬ëŸ¼ ìˆ˜ (ê¸°ë³¸ê°’: ì „ì²´)')
    parser.add_argument('--gpu', type=str, default='True', help='GPU ì‚¬ìš© ì—¬ë¶€ (True/False)')
    parser.add_argument('--models', type=str, default=None, help='ì‚¬ìš©í•  ëª¨ë¸ ëª©ë¡ (ì½¤ë§ˆë¡œ êµ¬ë¶„)')
    parser.add_argument('--preset', type=str, default='medium_quality_faster_train', 
                        help='AutoGluon í”„ë¦¬ì…‹')
    parser.add_argument('--verbose', type=int, default=1, help='ì¶œë ¥ ìƒì„¸ ìˆ˜ì¤€ (0: ê°„ëµ, 1: ê¸°ë³¸, 2: ìƒì„¸)')
    args = parser.parse_args()
    
    # GPU ì„¤ì • ì²˜ë¦¬
    use_gpu = args.gpu.lower() == 'true'
    
    # ëª¨ë¸ ëª©ë¡ ì²˜ë¦¬
    selected_models = None
    if args.models:
        selected_models = args.models.split(',')
    
    # ë¡œê¹… ì„¤ì •
    # name for setup_logger
    name = "AutoGluon ML Pipeline"
    # with time executed
    start_time = time.time()
    name = f"{name} - {time.strftime('%Y%m%d_%H%M%S')}"
    logger = utils.setup_logger(name)
    logger.info("=== AutoGluon ML Pipeline Started ===")
    print("\nğŸš€ BidPrice ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        if not args.train_only and not args.evaluate_only:
            logger.info("Step 1: Loading and preprocessing data...")
            print("ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            # ì „ì²˜ë¦¬ ë‹¨ê³„ ì§„í–‰ í‘œì‹œê¸°
            preprocessing_steps = ['ë°ì´í„° ë¡œë“œ', 'ì¤‘ë³µ ì œê±°', 'ê²°ì¸¡ì¹˜ ì²˜ë¦¬', 'í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• ', 'ë°ì´í„° ì €ì¥']
            preprocess_pbar = tqdm(preprocessing_steps, desc="ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬", position=0, leave=True)
            
            # ë°ì´í„° ë¡œë“œ
            preprocess_pbar.set_description("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘")
            data = data_processing.load_data()
            preprocess_pbar.update(1)
            
            # ì¤‘ë³µ ì œê±° ë° ì „ì²˜ë¦¬
            preprocess_pbar.set_description("ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ (ì¤‘ë³µ ì œê±°)")
            X, Y = data_processing.preprocess_data(data)
            preprocess_pbar.update(1)
            
            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            preprocess_pbar.set_description("ğŸ“Š ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì¤‘")
            time.sleep(1)  # ì‹¤ì œë¡œëŠ” í•„ìš” ì—†ì§€ë§Œ ì§„í–‰ ìƒí™©ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ì§€ì—°
            preprocess_pbar.update(1)
            
            # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í•  ë° ì €ì¥
            preprocess_pbar.set_description("ğŸ“Š ë°ì´í„° ë¶„í•  ì¤‘")
            train_X, test_X, train_Y, test_Y = data_processing.split_and_save_data(X, Y)
            preprocess_pbar.update(2)
            
            print(f"\nâœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ! í•™ìŠµ ë°ì´í„°: {train_X.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_X.shape}\n")
            
            if args.data_only:
                logger.info("Data processing only mode - exiting")
                print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ë§Œ ìˆ˜í–‰í•˜ë„ë¡ ì„¤ì •ë˜ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return
        else:
            logger.info("Loading preprocessed data...")
            print("ğŸ’¾ ì €ì¥ëœ ì „ì²˜ë¦¬ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
            train_X, test_X, train_Y, test_Y = data_processing.load_processed_data()
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ! í•™ìŠµ ë°ì´í„°: {train_X.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_X.shape}\n")
        
        # 2. ëª¨ë¸ í•™ìŠµ
        if not args.data_only and not args.evaluate_only:
            logger.info("Step 2: Training models...")
            print("ğŸ§  ëª¨ë¸ í•™ìŠµ ë‹¨ê³„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            # íƒ€ê²Ÿ ìˆ˜ ê²°ì •
            target_columns = train_Y.columns
            if args.num_targets is not None:
                target_columns = target_columns[:args.num_targets]
            
            # íƒ€ê²Ÿë³„ í•™ìŠµ ì§„í–‰ í‘œì‹œê¸°
            train_pbar = tqdm(total=len(target_columns), desc="ğŸ§  ëª¨ë¸ í•™ìŠµ", position=0, leave=True)
            
            model_paths = []
            for i, target_col in enumerate(target_columns):
                train_pbar.set_description(f"ğŸ§  [{i+1}/{len(target_columns)}] {target_col} í•™ìŠµ ì¤‘")
                
                # ëª¨ë¸ë³„ í•™ìŠµ ì§„í–‰ í‘œì‹œê¸° (GPU ì‚¬ìš© ì‹œ í‘œì‹œ)
                if use_gpu and args.verbose > 0:
                    print(f"  ğŸ”¥ GPUë¥¼ ì‚¬ìš©í•˜ì—¬ {target_col} í•™ìŠµ ì¤‘...")
                
                # ë‹¨ì¼ íƒ€ê²Ÿ í•™ìŠµ
                model_path = train.train_single_target_model(
                    train_X, train_Y, target_col,
                    use_gpu=use_gpu,
                    selected_models=selected_models,
                    preset=args.preset
                )
                model_paths.append(model_path)
                
                # í•™ìŠµ ê²°ê³¼ ê°„ëµ ì¶œë ¥
                if args.verbose > 0:
                    print(f"  âœ… {target_col} ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: {model_path}")
                
                train_pbar.update(1)
            
            train_pbar.close()
            print(f"\nâœ… ì´ {len(model_paths)}ê°œ íƒ€ê²Ÿì— ëŒ€í•œ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n")
            
            if args.train_only:
                logger.info("Training only mode - exiting")
                print("âœ… ëª¨ë¸ í•™ìŠµë§Œ ìˆ˜í–‰í•˜ë„ë¡ ì„¤ì •ë˜ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return
        
        # 3. ëª¨ë¸ í‰ê°€
        if not args.data_only and not args.train_only:
            logger.info("Step 3: Evaluating models...")
            print("ğŸ“ˆ ëª¨ë¸ í‰ê°€ ë‹¨ê³„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            # í‰ê°€í•  íƒ€ê²Ÿ ìˆ˜ ê²°ì •
            target_columns = test_Y.columns
            if args.num_targets is not None:
                target_columns = target_columns[:args.num_targets]
            
            # íƒ€ê²Ÿë³„ í‰ê°€ ì§„í–‰ í‘œì‹œê¸°
            eval_pbar = tqdm(total=len(target_columns), desc="ğŸ“ˆ ëª¨ë¸ í‰ê°€", position=0, leave=True)
            
            all_results = []
            for i, target_col in enumerate(target_columns):
                eval_pbar.set_description(f"ğŸ“ˆ [{i+1}/{len(target_columns)}] {target_col} í‰ê°€ ì¤‘")
                
                # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
                model_path = os.path.join(config.MODEL_DIR, target_col)
                if not os.path.exists(model_path):
                    logger.warning(f"Model for {target_col} not found at {model_path}")
                    eval_pbar.update(1)
                    continue
                
                # í‰ê°€ ê³¼ì • í‘œì‹œê¸° (ìƒì„¸ ëª¨ë“œì—ì„œë§Œ)
                if args.verbose > 1:
                    eval_steps = ['ëª¨ë¸ ë¡œë“œ', 'ì˜ˆì¸¡ ìˆ˜í–‰', 'ì„±ëŠ¥ ê³„ì‚°', 'ì‹œê°í™” ìƒì„±', 'ê²°ê³¼ ì €ì¥']
                    eval_step_pbar = tqdm(eval_steps, desc=f"  {target_col} í‰ê°€", position=1, leave=False)
                    
                    # ê° í‰ê°€ ë‹¨ê³„ ì‹œê°í™”
                    for step in eval_steps:
                        eval_step_pbar.set_description(f"  {step} ì¤‘")
                        time.sleep(0.5)  # ì‹¤ì œë¡œëŠ” í•„ìš” ì—†ì§€ë§Œ ì§„í–‰ ìƒí™©ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ì§€ì—°
                        eval_step_pbar.update(1)
                    
                    eval_step_pbar.close()
                
                # ëª¨ë¸ í‰ê°€
                results = evaluate.evaluate_model(
                    model_path=model_path, 
                    test_X=test_X, 
                    test_Y=test_Y, 
                    target_col=target_col
                )
                
                # ê°„ëµí•œ ê²°ê³¼ ì¶œë ¥
                if args.verbose > 0:
                    best_model = utils.get_best_model(results, 'r2_score')
                    best_r2 = results[results['model'] == best_model]['r2_score'].values[0]
                    print(f"  âœ… {target_col} í‰ê°€ ì™„ë£Œ - ìµœê³  ëª¨ë¸: {best_model} (RÂ²: {best_r2:.4f})")
                
                all_results.append(results)
                eval_pbar.update(1)
            
            eval_pbar.close()
            
            # ê²°ê³¼ ê²°í•©
            if all_results:
                combined_results = pd.concat(all_results, ignore_index=True)
                
                # ìš”ì•½ ì €ì¥
                summary_path = os.path.join(config.RESULTS_DIR, "all_models_evaluation.csv")
                combined_results.to_csv(summary_path, index=False)
                
                # í‰ê·  ì„±ëŠ¥ ì¶œë ¥
                avg_performance = combined_results.groupby('model')[config.METRICS].mean()
                print("\nğŸ“Š ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥:")
                print(avg_performance)
                
                print(f"\nâœ… ì´ {len(target_columns)}ê°œ íƒ€ê²Ÿì— ëŒ€í•œ ëª¨ë¸ í‰ê°€ ì™„ë£Œ!")
                print(f"ğŸ“„ ì¢…í•© ê²°ê³¼ê°€ {summary_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
            else:
                print("\nâš ï¸ í‰ê°€í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•´ì£¼ì„¸ìš”.\n")
        
        logger.info("=== Pipeline completed successfully ===")
        print("\nğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        logger.error(f"Error in pipeline: {e}", exc_info=True)
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise

if __name__ == "__main__":
    main() 