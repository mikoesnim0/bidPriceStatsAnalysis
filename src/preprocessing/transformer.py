import pandas as pd
import numpy as np
import logging
from sklearn.preprocessing import StandardScaler, MinMaxScaler

logger = logging.getLogger(__name__)

class DataTransformer:
    """ë°ì´í„° ë³€í™˜ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.scalers = {}  # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
    
    def transform_dataset(self, df, dataset_name):
        """
        ë°ì´í„°ì…‹ ë³€í™˜ ìˆ˜í–‰
        
        Parameters:
            df (DataFrame): ë³€í™˜í•  ë°ì´í„°í”„ë ˆì„
            dataset_name (str): ë°ì´í„°ì…‹ ì´ë¦„
            
        Returns:
            DataFrame: ë³€í™˜ëœ ë°ì´í„°í”„ë ˆì„
        """
        logger.info(f"ğŸ”„ {dataset_name} ë°ì´í„°ì…‹ ë³€í™˜ ì‹œì‘")
        
        # 1. ë¡œê·¸ ë³€í™˜ (ê¸ˆì•¡ ì»¬ëŸ¼ ë“±)
        df = self._apply_log_transform(df)
        
        # 2. ìŠ¤ì¼€ì¼ë§ (ì •ê·œí™”/í‘œì¤€í™”)
        df = self._apply_scaling(df, dataset_name)
        
        # 3. ì¸ì½”ë”© (ë²”ì£¼í˜• ë³€ìˆ˜)
        df = self._encode_categorical_features(df)
        
        logger.info(f"âœ… {dataset_name} ë°ì´í„°ì…‹ ë³€í™˜ ì™„ë£Œ")
        return df
    
    def _apply_log_transform(self, df):
        """ê¸ˆì•¡ ê´€ë ¨ ì»¬ëŸ¼ì— ë¡œê·¸ ë³€í™˜ ì ìš©"""
        # ê¸ˆì•¡ ê´€ë ¨ ì»¬ëŸ¼ ì‹ë³„
        amount_columns = []
        for col in df.select_dtypes(include=['int64', 'float64']).columns:
            if any(keyword in col for keyword in ['ê¸ˆì•¡', 'price', 'amount', 'ë¹„ìš©']):
                # 0 ì´í•˜ ê°’ì´ ìˆëŠ”ì§€ í™•ì¸ (ë¡œê·¸ ë³€í™˜ì„ ìœ„í•´)
                if (df[col] <= 0).any():
                    # 0 ì´í•˜ ê°’ì´ ìˆìœ¼ë©´ ëª¨ë“  ê°’ì— ì‘ì€ ê°’ì„ ë”í•´ ì–‘ìˆ˜ë¡œ ë§Œë“¦
                    min_val = abs(df[col].min()) + 1 if df[col].min() <= 0 else 0
                    logger.info(f"âš ï¸ '{col}' ì»¬ëŸ¼ì— 0 ì´í•˜ ê°’ì´ ìˆì–´ {min_val} ì¶”ê°€")
                    df[f"norm_log_{col}"] = np.log1p(df[col] + min_val)
                else:
                    df[f"norm_log_{col}"] = np.log1p(df[col])
                
                amount_columns.append(col)
                logger.info(f"âœ… '{col}' ì»¬ëŸ¼ì— ë¡œê·¸ ë³€í™˜ ì ìš© -> 'norm_log_{col}'")
        
        return df
    
    def _apply_scaling(self, df, dataset_name):
        """ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì— ìŠ¤ì¼€ì¼ë§ ì ìš©"""
        # ìŠ¤ì¼€ì¼ë§í•  ì»¬ëŸ¼ ì„ íƒ (norm_log_ ì ‘ë‘ì‚¬ í¬í•¨)
        scaling_cols = [
            col for col in df.select_dtypes(include=['int64', 'float64']).columns
            if not any(keyword in col for keyword in ['id', 'ID', 'ë²ˆí˜¸', 'index'])
        ]
        
        if scaling_cols:
            # MinMaxScaler ì ìš© (0~1 ë²”ìœ„ë¡œ ì •ê·œí™”)
            scaler = MinMaxScaler()
            
            # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ê²½ìš° ëŒ€ì²´
            df_scaled = df.copy()
            for col in scaling_cols:
                if df[col].isna().any():
                    df_scaled[col] = df[col].fillna(df[col].median())
            
            # ìŠ¤ì¼€ì¼ë§ ì ìš©
            df_scaled[scaling_cols] = scaler.fit_transform(df_scaled[scaling_cols])
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ (ë‚˜ì¤‘ì— í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜ì— ì‚¬ìš©)
            self.scalers[dataset_name] = {
                'scaler': scaler,
                'columns': scaling_cols
            }
            
            logger.info(f"âœ… {len(scaling_cols)}ê°œ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì— MinMaxScaler ì ìš©")
            
            return df_scaled
        
        return df
    
    def _encode_categorical_features(self, df):
        """ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©"""
        # ë²”ì£¼í˜• ì»¬ëŸ¼ (ë¬¸ìì—´ íƒ€ì…) ì„ íƒ
        cat_columns = df.select_dtypes(include=['object']).columns
        
        if len(cat_columns) > 0:
            logger.info(f"ğŸ”„ {len(cat_columns)}ê°œ ë²”ì£¼í˜• ì»¬ëŸ¼ ì¸ì½”ë”©")
            
            # ì›-í•« ì¸ì½”ë”© ì ìš© (ë²”ì£¼ ìˆ˜ê°€ ì ì€ ì»¬ëŸ¼ì—ë§Œ)
            for col in cat_columns:
                unique_values = df[col].nunique()
                
                # ë²”ì£¼ ìˆ˜ê°€ 10ê°œ ì´í•˜ì¸ ê²½ìš°ì—ë§Œ ì›-í•« ì¸ì½”ë”© ì ìš©
                if 2 <= unique_values <= 10:
                    # ì›-í•« ì¸ì½”ë”©
                    dummies = pd.get_dummies(df[col], prefix=col, drop_first=False)
                    df = pd.concat([df, dummies], axis=1)
                    logger.info(f"âœ… '{col}' ì»¬ëŸ¼ì— ì›-í•« ì¸ì½”ë”© ì ìš© (ë²”ì£¼ ìˆ˜: {unique_values})")
        
        return df 