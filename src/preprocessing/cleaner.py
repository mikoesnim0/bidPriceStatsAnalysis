import pandas as pd
import numpy as np
import logging

logger = logging.getLogger(__name__)

class DataCleaner:
    """ë°ì´í„° ì •ì œë¥¼ ìœ„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.cleaning_stats = {}
    
    def clean_dataset(self, df, dataset_name):
        """
        ë°ì´í„°ì…‹ ì •ì œ ìˆ˜í–‰
        
        Parameters:
            df (DataFrame): ì •ì œí•  ë°ì´í„°í”„ë ˆì„
            dataset_name (str): ë°ì´í„°ì…‹ ì´ë¦„
            
        Returns:
            DataFrame: ì •ì œëœ ë°ì´í„°í”„ë ˆì„
        """
        logger.info(f"ğŸ§¹ {dataset_name} ë°ì´í„°ì…‹ ì •ì œ ì‹œì‘")
        original_shape = df.shape
        
        # ì •ì œ í†µê³„ ì´ˆê¸°í™”
        self.cleaning_stats[dataset_name] = {
            'original_rows': original_shape[0],
            'original_columns': original_shape[1],
            'missing_values_removed': 0,
            'duplicates_removed': 0
        }
        
        # 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df_cleaned = self._handle_missing_values(df, dataset_name)
        
        # 2. ì¤‘ë³µ ë°ì´í„° ì œê±°
        df_cleaned = self._remove_duplicates(df_cleaned, dataset_name)
        
        # 3. ì´ìƒì¹˜ ì²˜ë¦¬
        df_cleaned = self._handle_outliers(df_cleaned, dataset_name)
        
        # 4. ë°ì´í„° íƒ€ì… ë³€í™˜
        df_cleaned = self._convert_dtypes(df_cleaned)
        
        # ìµœì¢… ë°ì´í„°ì…‹ í¬ê¸° ë° ì •ì œ í†µê³„ ê¸°ë¡
        final_shape = df_cleaned.shape
        self.cleaning_stats[dataset_name]['final_rows'] = final_shape[0]
        self.cleaning_stats[dataset_name]['final_columns'] = final_shape[1]
        
        logger.info(f"âœ… {dataset_name} ë°ì´í„°ì…‹ ì •ì œ ì™„ë£Œ")
        logger.info(f"   - ì›ë³¸ í¬ê¸°: {original_shape[0]} í–‰ x {original_shape[1]} ì—´")
        logger.info(f"   - ì •ì œ í›„ í¬ê¸°: {final_shape[0]} í–‰ x {final_shape[1]} ì—´")
        logger.info(f"   - ì œê±°ëœ ê²°ì¸¡ì¹˜ í–‰: {self.cleaning_stats[dataset_name]['missing_values_removed']}")
        logger.info(f"   - ì œê±°ëœ ì¤‘ë³µ í–‰: {self.cleaning_stats[dataset_name]['duplicates_removed']}")
        
        return df_cleaned
    
    def _handle_missing_values(self, df, dataset_name):
        """ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
        # ê²°ì¸¡ì¹˜ í™•ì¸
        missing_counts = df.isna().sum()
        total_missing = missing_counts.sum()
        
        if total_missing > 0:
            logger.info(f"âš ï¸ {dataset_name}ì—ì„œ ì´ {total_missing}ê°œì˜ ê²°ì¸¡ì¹˜ ë°œê²¬")
            
            # í•„ìˆ˜ ì»¬ëŸ¼ì— ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ ì œê±°
            # 'ê³µê³ ë²ˆí˜¸'ì™€ ê°™ì€ í•„ìˆ˜ ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ í•´ë‹¹ ì»¬ëŸ¼ì— ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ ì œê±°
            essential_columns = ['ê³µê³ ë²ˆí˜¸']  # í•„ìˆ˜ ì»¬ëŸ¼ ëª©ë¡
            essential_columns = [col for col in essential_columns if col in df.columns]
            
            if essential_columns:
                missing_in_essential = df[essential_columns].isna().any(axis=1)
                rows_to_drop = missing_in_essential.sum()
                
                if rows_to_drop > 0:
                    logger.info(f"âš ï¸ í•„ìˆ˜ ì»¬ëŸ¼ì— ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” {rows_to_drop}ê°œ í–‰ ì œê±°")
                    df = df[~missing_in_essential]
                    self.cleaning_stats[dataset_name]['missing_values_removed'] += rows_to_drop
            
            # ë‚˜ë¨¸ì§€ ê²°ì¸¡ì¹˜ëŠ” ì ì ˆí•œ ê°’ìœ¼ë¡œ ëŒ€ì²´
            # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼: ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´
            numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
            for col in numeric_cols:
                if df[col].isna().sum() > 0:
                    median_val = df[col].median()
                    df[col] = df[col].fillna(median_val)
                    logger.info(f"   - '{col}' ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ë¥¼ ì¤‘ì•™ê°’ {median_val}ìœ¼ë¡œ ëŒ€ì²´")
            
            # ë¬¸ìì—´ ì»¬ëŸ¼: 'Unknown'ìœ¼ë¡œ ëŒ€ì²´
            string_cols = df.select_dtypes(include=['object']).columns
            for col in string_cols:
                if df[col].isna().sum() > 0:
                    df[col] = df[col].fillna('Unknown')
                    logger.info(f"   - '{col}' ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ë¥¼ 'Unknown'ìœ¼ë¡œ ëŒ€ì²´")
        
        return df
    
    def _remove_duplicates(self, df, dataset_name):
        """ì¤‘ë³µ ë°ì´í„° ì œê±°"""
        # 'ê³µê³ ë²ˆí˜¸'ì™€ ê°™ì€ ê³ ìœ  ì‹ë³„ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ í™•ì¸
        if 'ê³µê³ ë²ˆí˜¸' in df.columns:
            duplicates = df.duplicated(subset=['ê³µê³ ë²ˆí˜¸'], keep='first')
            dup_count = duplicates.sum()
            
            if dup_count > 0:
                logger.info(f"âš ï¸ {dataset_name}ì—ì„œ {dup_count}ê°œì˜ ì¤‘ë³µ í–‰ ë°œê²¬")
                df = df[~duplicates]
                self.cleaning_stats[dataset_name]['duplicates_removed'] = dup_count
        
        return df
    
    def _handle_outliers(self, df, dataset_name):
        """ì´ìƒì¹˜ ì²˜ë¦¬"""
        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì— ëŒ€í•´ IQR ë°©ì‹ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬
        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
        
        for col in numeric_cols:
            # ê¸ˆì•¡ì´ë‚˜ ìˆ˜ì¹˜ ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ ì´ìƒì¹˜ ì²˜ë¦¬ (ì˜ˆ: 'ê¸°ì´ˆê¸ˆì•¡', 'ì˜ˆì •ê¸ˆì•¡' ë“±)
            if any(keyword in col for keyword in ['ê¸ˆì•¡', 'price', 'amount', 'ë¹„ìš©']):
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                # ì´ìƒì¹˜ í™•ì¸
                outliers = ((df[col] < lower_bound) | (df[col] > upper_bound))
                outlier_count = outliers.sum()
                
                if outlier_count > 0:
                    logger.info(f"âš ï¸ '{col}' ì»¬ëŸ¼ì—ì„œ {outlier_count}ê°œì˜ ì´ìƒì¹˜ ë°œê²¬")
                    # ì´ìƒì¹˜ë¥¼ ê²½ê³„ê°’ìœ¼ë¡œ ëŒ€ì²´
                    df.loc[df[col] < lower_bound, col] = lower_bound
                    df.loc[df[col] > upper_bound, col] = upper_bound
                    logger.info(f"   - ì´ìƒì¹˜ë¥¼ ê²½ê³„ê°’ìœ¼ë¡œ ëŒ€ì²´ ({lower_bound:.2f} ~ {upper_bound:.2f})")
        
        return df
    
    def _convert_dtypes(self, df):
        """ë°ì´í„° íƒ€ì… ë³€í™˜"""
        # ë°ì´í„° íƒ€ì… ìµœì í™”
        for col in df.columns:
            # ë‚ ì§œ ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜
            if any(keyword in col.lower() for keyword in ['date', 'ë‚ ì§œ', 'ì¼ì', 'ì‹œì‘ì¼', 'ì¢…ë£Œì¼']):
                try:
                    df[col] = pd.to_datetime(df[col], errors='coerce')
                except:
                    pass
        
        return df 